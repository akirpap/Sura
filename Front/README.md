# FrontEnd
Este apartado tratar√° acerca del FrontEnd desarrollado en Angular 9 y los servicios de IBM Cloud usados, para un acercamiento al BackEnd, se puede dirigir al [readme](https://github.com/emeloibmco/Watson-NLU-WVR-Web-App/tree/master/Back/README.md) del BackEnd.

## Indice
1. [Arquitectura](#Arquitectura)
2. [Funcionamiento](#Funcionamiento)
   - [NLU](#NLU)
   - [VR](#VR)
3. [Conexi√≥n](#Conexi√≥n)
4. [Servicios](#Servicios)
   - [Natural Language Understanding Service](#Natural-Language-Understanding-Service)
   - [Watson Knowledge Studio Service](#Watson-Knowledge-Studio-Service)
   - [Watson Visual Recognition Service](#Watson-Visual-Recognition-Service)
5. [Despliegue](#Despliegue)
5. [Referencias](#Referencias)
6. [Autores](#Autores)

## Arquitectura
La arquitectura de la aplicaci√≥n se puede apreciar a continuaci√≥n

![](https://user-images.githubusercontent.com/25871322/79778536-7ab1d400-82fe-11ea-8e09-5c471265d5c3.png)

## Funcionamiento
Al realizar el front en Angular, es necesario entender que la aplicaci√≥n estar√° conformada por componentes, para este caso se realizan 4 componentes, de los cuales 2 tendr√°n la l√≥gica de funcionamiento y conexi√≥n con el back, [NLU](#NLU) y [VR](#VR).

### NLU
Este componente contiene los elementos visuales necesarios para que el usuario interactue con el servicio de Natural Language Understanding, como un cuadro de texto y un conjunto de cards por medio del cual se muestra los resultados recibidos desde el backend, y adquiridos a traves del servicio de NLU.

Al interior del componente adem√°s de la capa gr√°fica existe l√≥gica de fondo que permite interactuar con el usuario y con el backend, esto se logra por medio de 2 funciones principales, una encargada de conectarse con el backend y otra encargada de procesar la informaci√≥n recibida desde el mismo. Estas funciones denominadas sendText() y JSONHandler() respectivamente, se pueden encontrar en el archivo [nlu.component.ts](https://github.com/emeloibmco/Watson-NLU-WVR-Web-App/blob/master/Front/src/app/components/nlu/nlu.component.ts)

La configuraci√≥n del Natural Language Understanding y el Watson Knowledge Studio se encuentra en [Natural Language Undestanding Service](#Natural-Language-Undestanding-Service) y [Watson Knowledge Studio Service](#Watson-Knowledge-Studio-Service) respectivamente.

### VR
Al igual que el componente de NLU, este contiene los elementos visuales necesarios para que el usuario interactue con el servicio de Visual Recognition como un cuadro de drag'n drop y un conjunto de cards por medio del cual se muestra los resultados recibidos desde el servicio.

De igual forma, al interior del componente adem√°s de la capa gr√°fica existe l√≥gica de fondo que permite interactuar con el usuario y con el backend, sin embargo, adem√°s de hacer uso de 2 funciones para la conexi√≥n y procesamiento de la informaci√≥n recibida, tambi√©n se encuentran otras m√°s encargadas del manejo de archivos, dado que el manejo de im√°genes tiene un nivel de complejidad m√°s alto al de manejar s√≥lo texto, la l√≥gica del componente se puede encontrar en el archivo [vr.component.ts](https://github.com/emeloibmco/Watson-NLU-WVR-Web-App/blob/master/Front/src/app/components/vr/vr.component.ts)

La configuraci√≥n del Watson Visual Recognition se encuentra en [Watson Visual Recognition Service](#Watson-Visual-Recognition-Service).

## Conexi√≥n
Al interior de los anteriores componente se realiza una comunicaci√≥n con el back a partir de un llamado POST a la URL en la cual se encuentre desplegado el back, esto se puede determinar en el archivo [nlu.component.ts](https://github.com/emeloibmco/Watson-NLU-WVR-Web-App/blob/master/Front/src/app/components/nlu/nlu.component.ts) para el caso de NLU o en [vr.component.ts](https://github.com/emeloibmco/Watson-NLU-WVR-Web-App/blob/master/Front/src/app/components/vr/vr.component.ts) para el caso del VR.

```javascript
	URL = "direcci√≥n del BackEnd"
```
Es importante cambiar esta URL por la del backend, la cual puede diferenciarse dependiendo de donde se haya desplegado.

## Servicios
Como ya se hab√≠a descrito, la aplicaci√≥n cuenta con 3 servicios de IBM Cloud: Natural Language Understanding, Watson Knowledge Studio y Watson Visual Recognition.

### Natural Language Understanding Service


### Watson Knowledge Studio Service


### Watson Visual Recognition Service

IBM Watson Visual Recognition es una herramienta que utiliza algoritmos de machine learning, permitiendo a los usuarios identificar autom√°ticamente sujetos, objetos, contenidos en la imagen, organizar y clasificar dichas im√°genes en categor√≠as l√≥gicas.
Este servicio es muy intuitivo, sus resultados son detallados y r√°pidos debido a que los modelos est√°n ampliamnete entrenados.

### 1. Informaci√≥n B√°sicos: üìå
Watson ofrece los siguientes modelos con resultados precisos:

- Modelo General: clasificaci√≥n predeterminada procedente de miles de clases.
- Modelo expl√≠cito: si una imagen resulta inadecuada para uso general.
- Modelo de alimentos: espec√≠fico para im√°genes de alimentos.

*Tambi√©n puede entrenar modelos personalizados para crear clases especializadas.*

Proceso de crear y utilizar Visual Recognition:
![20](https://user-images.githubusercontent.com/44415995/79902405-10209700-83d7-11ea-8529-0c4972a649d1.PNG)


### 2. Pre-Requisitos üìã

#### A).

Iniciar sesi√≥n en su cuenta IBM Cloud, si no tiene cuenta puede crear una. 

[CREAR CUENTA IBM CLOUD](https://cloud.ibm.com/registration)

#### B).

En la secci√≥n de cat√°logo busque  Visual Recognition y seleccione dicho servicio.

<img src="https://user-images.githubusercontent.com/56199403/79892028-769db900-83c7-11ea-8607-5cbdc9a7ccce.jpg" width="600">

#### C).

Para crear el servicio lo primero se realiza es seleccionar la regi√≥n, para esta gu√≠a se seleccion√≥ Dallas, posteriormente elija el plan que se acomode mejor a sus necesidades. Asignele un nombre a este servicio y por ultimo cree el servicio dando click al boton "create".


<img src="https://user-images.githubusercontent.com/56199403/79892286-f2980100-83c7-11ea-873f-e44f6d76e44f.jpg" width="700">




### 3. Visual Recongition por medio Watson Studio en IBM CLOUD üöÄ
### Caso de uso:
Las empresas est√°n resolviendo sus desaf√≠os √∫nicos mediante el uso de modelos personalizados para reconocer cualquier objeto, escena o atributo. Para este caso utilizaremos modelos personalizados para generar autom√°ticamente estimaciones de los costos de reparaci√≥n basados en im√°genes de da√±os en el autom√≥vil enviadas a medida.

#### Paso 1:
Seleccione el servicio de Visual Recognition, este se identifica con el siguiente icono <img src="https://user-images.githubusercontent.com/56199403/79884639-06893600-83bb-11ea-9d2e-381ac03c1d58.jpg" width="50">


#### Paso 2:
Posteriormente se debe dar clic en ‚ÄúLaunch Watson Studio‚Äù, y en la nueva pesta√±a que se carg√≥ seleccionamos el tipo de modelo que se desea utilizar, para esta gu√≠a se utiliz√≥ ‚ÄúClassify Images‚Äù.

<img src="https://user-images.githubusercontent.com/56199403/79890486-2f162d80-83c5-11ea-8011-261da082c822.jpg" width="600">

#### Paso 3:
Ahora procedemos a subir al modelo el set de im√°genes positivas, las cuales proporcionar√°n ejemplos de im√°genes reales de objetos para clasificar como miembros de esa clase.

![Image 2](https://user-images.githubusercontent.com/56199403/79903494-cb95fb00-83d8-11ea-8363-159200506f83.jpg ) 


*Nota: Hay que tener en cuenta que el n√∫mero m√≠nimo recomendado de im√°genes para tener en los conjuntos de im√°genes positivas antes de evaluar los resultados de la prueba es de 50 im√°genes y los formatos que acepta el modelo son .jpeg, .png, o .zip* üí°

#### Paso 4:
Una vez cargado el set positivo, se selecciona la clase ‚ÄúNegative‚Äù e ingresamos el set de im√°genes negativas, que son ejemplos de im√°genes reales de objetos para NO ser clasificados como miembros de esa clase.

#### Paso 5:
Procedemos a entrenar seleccionando el siguiente bot√≥n  <img src="https://user-images.githubusercontent.com/56199403/79891459-a26c6f00-83c6-11ea-8cf5-c8d87b52adec.jpg" width="90">


#### Paso 6:
Una vez entrenado el modelo, seleccionamos la opci√≥n de "Test" y probamos el modelo

## Aplicaci√≥n
La aplicaci√≥n se encuentra actualmente desplegada desde IBM Cloud Foundry y se puede acceder a ella a trav√©s del siguiente enlace:
https://ibmcrashapp.mybluemix.net/

## Referencias
-[Watson-Visual Recognition](https://www.ibm.com/co-es/cloud/watson-visual-recognition)


## Autores
*Equipo IBM Cloud Tech sales Colombia.*


